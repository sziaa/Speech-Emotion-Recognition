# Speech-Emotion-Recognition
In this project, the goal was to develop a machine learning model capable of recognizing emotions from audio recordings of speech in real-time. We use a limited version of the Ryerson Audio-Visual Database of Emotional Speech and Song dataset to train the model.

Download the file here: https://drive.google.com/file/d/1wWsrN2Ep7x6lWqOXfr4rpKGYrJhWc8z7/view 

<img width="345" alt="Enter the path to the audio file" src="https://github.com/user-attachments/assets/3da0767d-0849-41c0-baea-6797ff9cf2f1">

# Requirements: 
- Python 3.5 or above
- librosa
- soundfile
- numpy
- scikit-learn
- portaudio
- pyaudio

Clone the repository and run SER_CODE.ipynb. At the end of the code, input your file path for the audio file you want to test and enter.

References: 
DataFlair: https://data-flair.training/blogs/python-mini-project-speech-emotion-recognition/#goog_rewarded 
